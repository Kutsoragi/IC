{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-igraph[all] in c:\\users\\morwar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.10.4)\n",
      "Requirement already satisfied: igraph==0.10.4 in c:\\users\\morwar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-igraph[all]) (0.10.4)\n",
      "Requirement already satisfied: texttable>=1.6.2 in c:\\users\\morwar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from igraph==0.10.4->python-igraph[all]) (1.6.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: python-igraph 0.10.4 does not provide the extra 'all'\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\Morwar\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycairo in c:\\users\\morwar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.23.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\Morwar\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-igraph[all]\n",
    "!pip install pycairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycairo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39migraph\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpycairo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39migraph\u001b[39;00m \u001b[39mimport\u001b[39;00m Graph, EdgeSeq\n\u001b[0;32m      8\u001b[0m \u001b[39m# Abre el archivo\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycairo'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import igraph\n",
    "import pycairo\n",
    "from igraph import Graph, EdgeSeq\n",
    "\n",
    "\n",
    "# Abre el archivo\n",
    "with open('AtributosJuego.txt', 'r') as archivo:\n",
    "\n",
    "    # Lee el contenido del archivo\n",
    "    contenido = archivo.read()\n",
    "\n",
    "    # Separa los strings por comas y guárdalos en una lista\n",
    "    atributos = contenido.split(',')\n",
    "\n",
    "# Cierra el archivo\n",
    "archivo.close()\n",
    "dataset= pd.read_csv(\"Juego.txt\", sep= \",\",names=atributos, decimal=',', header=None)\n",
    "\n",
    "#aqui tenemos ya nuestro dataset hecho\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula la entropía total del dataset\n",
    "def calc_total_entropy(datos, decisión, class_list):\n",
    "    total_row = datos.shape[0] #the total size of the dataset\n",
    "    total_entr = 0\n",
    "    \n",
    "    for c in class_list: #for each class in the decisión\n",
    "        total_class_count = datos[datos[decisión] == c].shape[0] #number of the class\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\n",
    "    \n",
    "    return total_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcula la entropía de la class list data\n",
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "    \n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c \n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "    \n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
    "        \n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "    feature_list = train_data.columns.drop(label) #finding the feature names in the dataset\n",
    "                                            #N.B. label is not a feature, so dropping it\n",
    "    max_info_gain = -1\n",
    "    max_info_feature = None\n",
    "    \n",
    "    for feature in feature_list:  #for each feature in the dataset\n",
    "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "        if max_info_gain < feature_info_gain: #selecting feature name with highest information gain\n",
    "            max_info_gain = feature_info_gain\n",
    "            max_info_feature = feature\n",
    "            \n",
    "    return max_info_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n",
    "    tree = {} #sub tree or node\n",
    "    \n",
    "    for feature_value, count in feature_value_count_dict.iteritems():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n",
    "        \n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
    "        for c in class_list: #for each class\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n",
    "\n",
    "            if class_count == count: #count of (feature_value = count) of class (pure class)\n",
    "                tree[feature_value] = c #adding node to the tree\n",
    "                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node: #not pure class\n",
    "            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further, \n",
    "                                      #so the branch is marking with ?\n",
    "            \n",
    "    return tree, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0: #if dataset becomes enpty after updating\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n",
    "        next_root = None\n",
    "        \n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "        \n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\n",
    "            if branch == \"?\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
    "    tree = {} #tree which will be updated\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
    "    make_tree(tree, None, train_data, label, class_list) #start calling recursion\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TiempoExterior': {'soleado': {'Humedad': {'alta': 'no', 'normal': 'si'}}, 'nublado': 'si', 'lluvioso': {'Viento': {'falso': 'si', 'verdad': 'no'}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Morwar\\AppData\\Local\\Temp\\ipykernel_12236\\122557810.py:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for feature_value, count in feature_value_count_dict.iteritems():\n",
      "C:\\Users\\Morwar\\AppData\\Local\\Temp\\ipykernel_12236\\122557810.py:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for feature_value, count in feature_value_count_dict.iteritems():\n",
      "C:\\Users\\Morwar\\AppData\\Local\\Temp\\ipykernel_12236\\122557810.py:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for feature_value, count in feature_value_count_dict.iteritems():\n"
     ]
    }
   ],
   "source": [
    "tree = id3(dataset, 'Jugar')\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Plotting not available; please install pycairo or cairocffi",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# Dibujar el grafo\u001b[39;00m\n\u001b[0;32m     14\u001b[0m layout \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mlayout(\u001b[39m\"\u001b[39m\u001b[39mtree\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m igraph\u001b[39m.\u001b[39;49mplot(g, layout\u001b[39m=\u001b[39;49mlayout, bbox\u001b[39m=\u001b[39;49m(\u001b[39m400\u001b[39;49m, \u001b[39m400\u001b[39;49m), margin\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, vertex_label\u001b[39m=\u001b[39;49mg\u001b[39m.\u001b[39;49mvs[\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m], edge_label\u001b[39m=\u001b[39;49mg\u001b[39m.\u001b[39;49mes[\u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\igraph\\drawing\\__init__.py:284\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(obj, target, bbox, *args, **kwds)\u001b[0m\n\u001b[0;32m    282\u001b[0m background \u001b[39m=\u001b[39m kwds\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mbackground\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m margin \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(kwds\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmargin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m20\u001b[39m))\n\u001b[1;32m--> 284\u001b[0m result \u001b[39m=\u001b[39m CairoPlot(\n\u001b[0;32m    285\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[0;32m    286\u001b[0m     bbox\u001b[39m=\u001b[39;49mbbox,\n\u001b[0;32m    287\u001b[0m     palette\u001b[39m=\u001b[39;49mpalette,\n\u001b[0;32m    288\u001b[0m     background\u001b[39m=\u001b[39;49mbackground,\n\u001b[0;32m    289\u001b[0m )\n\u001b[0;32m    290\u001b[0m item_bbox \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mbbox\u001b[39m.\u001b[39mcontract(margin)\n\u001b[0;32m    291\u001b[0m result\u001b[39m.\u001b[39madd(obj, item_bbox, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\igraph\\drawing\\cairo\\plot.py:148\u001b[0m, in \u001b[0;36mCairoPlot.__init__\u001b[1;34m(self, target, bbox, palette, background)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_tmpfile \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_surface \u001b[39m=\u001b[39m cairo\u001b[39m.\u001b[39;49mImageSurface(\n\u001b[0;32m    149\u001b[0m         cairo\u001b[39m.\u001b[39mFORMAT_ARGB32, \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbbox\u001b[39m.\u001b[39mwidth), \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbbox\u001b[39m.\u001b[39mheight)\n\u001b[0;32m    150\u001b[0m     )\n\u001b[0;32m    151\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(target, cairo\u001b[39m.\u001b[39mSurface):\n\u001b[0;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_surface \u001b[39m=\u001b[39m target\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\igraph\\drawing\\utils.py:428\u001b[0m, in \u001b[0;36mFakeModule.__getattr__\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, _):\n\u001b[1;32m--> 428\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Plotting not available; please install pycairo or cairocffi"
     ]
    }
   ],
   "source": [
    "# Crear el grafo\n",
    "g = igraph.Graph(directed=True)\n",
    "\n",
    "# Agregar los vértices al grafo\n",
    "g.add_vertices([\"TiempoExterior\", \"Humedad\", \"Viento\", \"No1\", \"Si1\", \"Si2\", \"No2\", \"Si3\"])\n",
    "\n",
    "# Agregar las aristas al grafo\n",
    "g.add_edges([(\"TiempoExterior\", \"Humedad\"), (\"TiempoExterior\", \"Viento\"), (\"Humedad\", \"No1\"), (\"Humedad\", \"Si1\"), (\"TiempoExterior\",\"Si2\"), (\"Viento\", \"No2\"), (\"Viento\", \"Si3\")])\n",
    "\n",
    "# Establecer las etiquetas de las aristas\n",
    "g.es[\"label\"] = [\"Soleado\", \"Lluvioso\", \"Alta\", \"Baja\", \"Nublado\", \"Verdad\", \"Falso\"]\n",
    "\n",
    "# Dibujar el grafo\n",
    "layout = g.layout(\"tree\")\n",
    "igraph.plot(g, layout=layout, bbox=(400, 400), margin=20, vertex_label=g.vs[\"name\"], edge_label=g.es[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict): #if it is leaf node\n",
    "        return tree #return the value\n",
    "    else:\n",
    "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n",
    "        feature_value = instance[root_node] #value of the feature\n",
    "        if feature_value in tree[root_node]: #checking the feature value in current tree node\n",
    "            return predict(tree[root_node][feature_value], instance) #goto next feature\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_preditct = 0\n",
    "    wrong_preditct = 0\n",
    "    for index, row in test_data_m.iterrows(): #for each row in the dataset\n",
    "        result = predict(tree, test_data_m.iloc[index]) #predict the row\n",
    "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n",
    "            correct_preditct += 1 #increase correct count\n",
    "        else:\n",
    "            wrong_preditct += 1 #increase incorrect count\n",
    "    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_data_m = pd.read_csv(\"PlayTennis.csv\") #importing test dataset into dataframe\n",
    "\n",
    "accuracy = evaluate(tree, test_data_m, 'Jugar') #evaluating the test dataset\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
